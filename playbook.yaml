---
- hosts: all
  vars:
    suffix: "{{ ansible_date_time.year }}-{{ ansible_date_time.month }}-{{ ansible_date_time.day }}_{{ ansible_date_time.hour }}{{ ansible_date_time.minute }}"
    # Default paths - can be overridden in host_vars or group_vars
    mysqldump_path: "{{ mysqldump_binary | default('/opt/homebrew/bin/mysqldump') }}"
    gzip_path: "{{ gzip_binary | default('gzip') }}"
    cp_path: "{{ cp_binary | default('cp') }}"
  tasks:
    - name: Backup databases
      block:
        # Skip SSH connectivity checks for hosts with ansible_connection=local
        - name: Check if host is local
          set_fact:
            is_local_host: "{{ ansible_connection == 'local' }}"
        - name: determine hosts that are up
          wait_for_connection:
            timeout: 5
          vars:
            ansible_connection: ssh
          when: not is_local_host

        - name: add devices with connectivity to the "running_hosts" group
          group_by:
            key: "running_hosts"
          when: not is_local_host

        # Ensure backup directory exists for all hosts
        - name: check if backup root is accessible
          local_action:
            module: stat
            path: "{{ backup_root }}"
          register: backup_root_stat
          ignore_errors: yes

        - name: create backup root directory if needed
          local_action:
            module: file
            path: "{{ backup_root }}"
            state: directory
            mode: 0755
          when: not backup_root_stat.stat.exists
          ignore_errors: yes

        - name: ensure backup directory exists
          local_action:
            module: file
            path: "{{ backup_root }}/{{ inventory_hostname }}"
            state: directory
            mode: 0755
            recurse: yes
          register: backup_dir_result
          ignore_errors: yes

        - name: check backup directory creation result
          fail:
            msg: "Failed to create backup directory {{ backup_root }}/{{ inventory_hostname }}. Please check permissions or create the directory manually."
          when: backup_dir_result.failed and backup_dir_result.msg is defined

        # Remote database dump
        - name: dump remote databases
          shell: "{{ mysqldump_path }} -u{{ user }}{% if pass is defined and pass != '' %} -p{{ pass }}{% endif %} --skip-dump-date --skip-extended-insert --quick {{ item }} > {{ item }}.sql"
          loop: "{{ databases }}"
          when: not is_local_host

        # Local database dump
        - name: dump local databases
          local_action:
            module: shell
            cmd: "{{ mysqldump_path }} -u{{ user }}{% if pass is defined and pass != '' %} -p{{ pass }}{% endif %} --skip-dump-date --skip-extended-insert --quick {{ item }} > {{ backup_root }}/{{ inventory_hostname }}/{{ item }}.sql"
          loop: "{{ databases }}"
          when: is_local_host

        # For remote hosts, synchronize the files
        - name: sync from remote
          synchronize:
            src: "*.sql"
            dest: "{{ backup_root }}/{{ inventory_hostname }}/"
            mode: pull
          when: not is_local_host

        # Create timestamped copies
        - name: copy
          local_action: command {{ cp_path }} "{{ backup_root }}/{{ inventory_hostname }}/{{ item }}.sql" "{{ backup_root }}/{{ inventory_hostname }}/{{ item }}_{{ suffix }}.sql"
          loop: "{{ databases }}"

        # Compress the timestamped copies
        - name: compress
          local_action: command {{ gzip_path }} "{{ backup_root }}/{{ inventory_hostname }}/{{ item }}_{{ suffix }}.sql"
          loop: "{{ databases }}"

        # Cleanup remote SQL files
        - name: cleanup remote files
          file:
            path: "{{ item }}.sql"
            state: absent
          loop: "{{ databases }}"
          when: not is_local_host
          
        # Remove old backups
        - name: remove old backups
          local_action:
            module: find
            paths: "{{ backup_root }}/{{ inventory_hostname }}"
            patterns: "{{ item }}_*.sql.gz"
            age: "{{ retention_days | default(7) }}d"
            age_stamp: mtime
            recurse: no
          register: old_backups
          loop: "{{ databases }}"
          
        - name: delete old backups
          local_action:
            module: file
            path: "{{ item.1.path }}"
            state: absent
          loop: "{{ old_backups.results | subelements('files') }}"
          when: old_backups.results is defined
      rescue:
          - name: debug error
            debug: 
              msg: "cannot connect to {{inventory_hostname}}"

          - name: Check if terminal-notifier exists
            local_action: shell which terminal-notifier 2>/dev/null || echo "not-found"
            register: terminal_notifier_check
            changed_when: false

          - name: Check if osascript exists (macOS)
            local_action: shell which osascript 2>/dev/null || echo "not-found"
            register: osascript_check
            changed_when: false

          - name: Handle failure with terminal-notifier
            local_action: command terminal-notifier -title "Backup failed" -message "Could not backup databases for {{ inventory_hostname }}"
            when: terminal_notifier_check.stdout != "not-found"
            ignore_errors: yes
            
          - name: Handle failure with macOS notification
            local_action: shell osascript -e 'display notification "Could not backup databases for {{ inventory_hostname }}" with title "Backup failed"'
            when: terminal_notifier_check.stdout == "not-found" and osascript_check.stdout != "not-found"
            ignore_errors: yes

          - name: Log failure message
            local_action:
              module: debug
              msg: "Backup failed for {{ inventory_hostname }} - could not connect to host"
            when: terminal_notifier_check.stdout == "not-found" and osascript_check.stdout == "not-found"
